#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Google Sheetsã¨product_masterã®å®Œå…¨åŒæœŸï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åå¯¾å¿œç‰ˆï¼‰
"""

import requests
import csv
from io import StringIO
from supabase import create_client
from datetime import datetime, timezone
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

SUPABASE_URL = "https://equrcpeifogdrxoldkpe.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImVxdXJjcGVpZm9nZHJ4b2xka3BlIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzkxNjE2NTMsImV4cCI6MjA1NDczNzY1M30.ywOqf2BSf2PcIni5_tjJdj4p8E51jxBSrfD8BE8PAhQ"

SPREADSHEET_ID = "1mLg1N0a1wubEIdKSouiW_jDaWUnuFLBxj8greczuS3E"
MAPPING_GID = "1290908701"

def sync_complete_product_master():
    """Google Sheetsã¨product_masterã®å®Œå…¨åŒæœŸ"""
    logger.info("=== Google Sheetså®Œå…¨åŒæœŸé–‹å§‹ ===")
    
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # Google Sheetsã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
    try:
        csv_url = f"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/export?format=csv&gid={MAPPING_GID}"
        response = requests.get(csv_url, timeout=30)
        response.raise_for_status()
        
        if response.encoding != 'utf-8':
            response.encoding = 'utf-8'
        
        csv_data = StringIO(response.text)
        reader = csv.DictReader(csv_data)
        data = list(reader)
        
        logger.info(f"Google Sheetsãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(data)}è¡Œ")
        
    except Exception as e:
        logger.error(f"Google Sheetsãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False
    
    # Google Sheetsã®å®Ÿéš›ã®åˆ—åï¼ˆdebug_sheets_structure.py ã§ç¢ºèªæ¸ˆã¿ï¼‰
    SHEETS_COLUMNS = {
        'sequence': 'é€£ç•ª',
        'common_code': 'å…±é€šã‚³ãƒ¼ãƒ‰', 
        'jan_ean': 'JAN/EANã‚³ãƒ¼ãƒ‰',
        'product_name': 'åŸºæœ¬å•†å“å',
        'rakuten_sku': 'æ¥½å¤©SKU',
        'colorme_id': 'ã‚«ãƒ©ãƒ¼ãƒŸãƒ¼ID',
        'smaregi_id': 'ã‚¹ãƒãƒ¬ã‚¸ID',
        'yahoo_id': 'Yahooå•†å“ID',
        'amazon_asin': 'Amazon ASIN',
        'mercari_id': 'ãƒ¡ãƒ«ã‚«ãƒªå•†å“ID',
        'product_type': 'å•†å“ã‚¿ã‚¤ãƒ—',
        'remarks': 'å‚™è€ƒ'
    }
    
    success_count = 0
    error_count = 0
    created_count = 0
    updated_count = 0
    
    logger.info(f"å‡¦ç†é–‹å§‹: {len(data)}è¡Œ")
    
    for i, row in enumerate(data):
        try:
            # å„é …ç›®ã‚’å–å¾—
            sequence_number = row.get(SHEETS_COLUMNS['sequence'], '').strip()
            common_code = row.get(SHEETS_COLUMNS['common_code'], '').strip()
            jan_ean_code = row.get(SHEETS_COLUMNS['jan_ean'], '').strip()
            product_name = row.get(SHEETS_COLUMNS['product_name'], '').strip()
            rakuten_sku = row.get(SHEETS_COLUMNS['rakuten_sku'], '').strip()
            colorme_id = row.get(SHEETS_COLUMNS['colorme_id'], '').strip()
            smaregi_id = row.get(SHEETS_COLUMNS['smaregi_id'], '').strip()
            yahoo_product_id = row.get(SHEETS_COLUMNS['yahoo_id'], '').strip()
            amazon_asin = row.get(SHEETS_COLUMNS['amazon_asin'], '').strip()
            mercari_product_id = row.get(SHEETS_COLUMNS['mercari_id'], '').strip()
            product_type = row.get(SHEETS_COLUMNS['product_type'], '').strip() or 'å˜å“'
            remarks = row.get(SHEETS_COLUMNS['remarks'], '').strip()
            
            # å…±é€šã‚³ãƒ¼ãƒ‰ã¯å¿…é ˆ
            if not common_code or not common_code.startswith('CM'):
                continue
            
            # ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºï¼ˆæœ€åˆã®5è¡Œï¼‰
            if i < 5:
                logger.info(f"è¡Œ{i+1}: {common_code} - æ¥½å¤©:{rakuten_sku or 'ãªã—'}, Amazon:{amazon_asin or 'ãªã—'}")
            
            # sequence_numberã¯æ•°å€¤å¤‰æ›
            try:
                seq_num = int(sequence_number) if sequence_number.isdigit() else None
            except:
                seq_num = None
            
            # Supabaseã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿æº–å‚™
            mapping_data = {
                "sequence_number": seq_num,
                "common_code": common_code,
                "jan_ean_code": jan_ean_code or None,
                "product_name": product_name or f"å•†å“_{common_code}",
                "rakuten_sku": rakuten_sku or None,
                "colorme_id": colorme_id or None,  # å®Ÿéš›ã®ã‚«ãƒ©ãƒ å
                "smaregi_id": smaregi_id or None,
                "yahoo_product_id": yahoo_product_id or None,
                "amazon_asin": amazon_asin or None,
                "mercari_product_id": mercari_product_id or None,
                "product_type": product_type,
                "remarks": remarks or None,
                "is_active": True,
                "updated_at": datetime.now(timezone.utc).isoformat()
            }
            
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ç¢ºèª
            existing = supabase.table("product_master").select("id").eq("common_code", common_code).execute()
            
            if existing.data:
                # æ›´æ–°
                result = supabase.table("product_master").update(mapping_data).eq("common_code", common_code).execute()
                updated_count += 1
                action = "UPDATED"
            else:
                # æ–°è¦ä½œæˆ
                mapping_data["created_at"] = datetime.now(timezone.utc).isoformat()
                result = supabase.table("product_master").insert(mapping_data).execute()
                created_count += 1
                action = "CREATED"
            
            if result.data:
                success_count += 1
                
                # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æƒ…å ±
                platforms = []
                if rakuten_sku: platforms.append("æ¥½å¤©")
                if amazon_asin: platforms.append("Amazon") 
                if colorme_id: platforms.append("ã‚«ãƒ©ãƒ¼ãƒŸãƒ¼")
                if yahoo_product_id: platforms.append("Yahoo")
                
                platform_info = "+".join(platforms) if platforms else "ãªã—"
                logger.info(f"   {action}: {common_code} [{platform_info}]")
            else:
                error_count += 1
                logger.error(f"   FAILED: {common_code}")
                
        except Exception as e:
            error_count += 1
            logger.error(f"   ERROR è¡Œ{i+1}: {str(e)}")
    
    # çµæœçµ±è¨ˆ
    logger.info(f"\n=== å®Œå…¨åŒæœŸçµæœ ===")
    logger.info(f"å‡¦ç†æˆåŠŸ: {success_count}ä»¶")
    logger.info(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶") 
    logger.info(f"æ–°è¦ä½œæˆ: {created_count}ä»¶")
    logger.info(f"ãƒ‡ãƒ¼ã‚¿æ›´æ–°: {updated_count}ä»¶")
    
    # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥çµ±è¨ˆ
    logger.info(f"\n=== ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ çµ±è¨ˆ ===")
    rakuten_count = supabase.table("product_master").select("id", count="exact").not_.is_("rakuten_sku", "null").execute()
    amazon_count = supabase.table("product_master").select("id", count="exact").not_.is_("amazon_asin", "null").execute()
    colorme_count = supabase.table("product_master").select("id", count="exact").not_.is_("colorme_id", "null").execute()
    yahoo_count = supabase.table("product_master").select("id", count="exact").not_.is_("yahoo_product_id", "null").execute()
    
    logger.info(f"æ¥½å¤©SKU: {rakuten_count.count}ä»¶")
    logger.info(f"Amazon ASIN: {amazon_count.count}ä»¶") 
    logger.info(f"ã‚«ãƒ©ãƒ¼ãƒŸãƒ¼ID: {colorme_count.count}ä»¶")
    logger.info(f"Yahooå•†å“ID: {yahoo_count.count}ä»¶")
    
    return success_count > 0

def verify_sync_result():
    """åŒæœŸçµæœã‚’æ¤œè¨¼"""
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    logger.info("=== åŒæœŸçµæœæ¤œè¨¼ ===")
    
    # rakuten_skuãŒnullã ã£ãŸãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    logger.info("rakuten_skuãŒnullã®ãƒ‡ãƒ¼ã‚¿ç¢ºèª:")
    null_rakuten = supabase.table("product_master").select(
        "common_code, rakuten_sku, amazon_asin, colorme_id, product_name"
    ).is_("rakuten_sku", "null").limit(5).execute()
    
    for item in null_rakuten.data:
        other_platforms = []
        if item.get('amazon_asin'): other_platforms.append("Amazon")
        if item.get('colorme_id'): other_platforms.append("ã‚«ãƒ©ãƒ¼ãƒŸãƒ¼") 
        
        other_info = "+".join(other_platforms) if other_platforms else "ä»–ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãªã—"
        logger.info(f"  {item['common_code']}: æ¥½å¤©ãªã—, {other_info}")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    logger.info("\nå®Œå…¨ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€æ–°5ä»¶ï¼‰:")
    samples = supabase.table("product_master").select(
        "common_code, rakuten_sku, amazon_asin, colorme_id, yahoo_product_id, product_name"
    ).order("updated_at", desc=True).limit(5).execute()
    
    for item in samples.data:
        platforms = []
        if item.get('rakuten_sku'): platforms.append("æ¥½å¤©")
        if item.get('amazon_asin'): platforms.append("Amazon")
        if item.get('colorme_id'): platforms.append("ã‚«ãƒ©ãƒ¼ãƒŸãƒ¼")
        if item.get('yahoo_product_id'): platforms.append("Yahoo")
        
        platform_str = "+".join(platforms) if platforms else "ãªã—"
        logger.info(f"  {item['common_code']}: [{platform_str}] {item['product_name'][:30]}...")

if __name__ == "__main__":
    print("=== Google Sheetså®Œå…¨åŒæœŸï¼ˆå…¨ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œï¼‰ ===")
    
    result = sync_complete_product_master()
    
    if result:
        print("\nâœ… å®Œå…¨åŒæœŸæˆåŠŸ!")
        verify_sync_result()
        print("\nğŸ‰ Google Sheetsã®å…¨ãƒ‡ãƒ¼ã‚¿ãŒproduct_masterã«åŒæœŸã•ã‚Œã¾ã—ãŸ")
        print("æ¥½å¤©SKUã®nullå•é¡Œã‚‚è§£æ±ºã•ã‚Œã€Amazon/ã‚«ãƒ©ãƒ¼ãƒŸãƒ¼ç­‰ã‚‚è¿½åŠ ã•ã‚Œã¾ã—ãŸ")
    else:
        print("\nâŒ åŒæœŸã«å¤±æ•—ã—ã¾ã—ãŸ")